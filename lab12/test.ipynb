{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting dataset/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting dataset/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting dataset/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting dataset/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "dest_directory = 'dataset/mnist'\n",
    "# check the directory\n",
    "if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "# import data\n",
    "mnist = input_data.read_data_sets(\"dataset/mnist/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model (Softmax Regression)\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None, 784])  # flatten into vector of 28 x 28 = 784\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])  # true answers\n",
    "W = tf.Variable(tf.zeros([784, 10]))  # Weights\n",
    "b = tf.Variable(tf.zeros([10]))  # bias\n",
    "y_pred = tf.matmul(x, W) + b  # y = Wx + b\n",
    "\n",
    "# Define loss and optimizer\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_true, \n",
    "                                            logits=y_pred))  # our loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(\n",
    "    cross_entropy)  # our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.6%\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # initialize the variables we created\n",
    "  sess.run(tf.global_variables_initializer())  \n",
    "  # run the training step 1000 times\n",
    "  for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    # feed training data x and y_ for training\n",
    "    sess.run(train_step, feed_dict={\n",
    "            x: batch_xs,\n",
    "            y_true: batch_ys\n",
    "        })  \n",
    "\n",
    "  # Testing\n",
    "  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "  accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  accuracy = sess.run(accuracy_op, feed_dict={\n",
    "          x: mnist.test.images,\n",
    "          y_true: mnist.test.labels\n",
    "      })\n",
    "  # feed our testing data for testing\n",
    "  print('Accuracy: %.1f%%' % (accuracy * 100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our convolutions uses a stride of one and are zero padded so that the output is the same size as the input.\n",
    "# Our pooling is plain old max pooling over 2x2 blocks.\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(\n",
    "      x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [batch_size, height, width, channel]\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# First Convolutional Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) # (filter_height, filter_width, number of input channels, number of output channels)\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# convolve x_image with the weight tensor, add the bias, then apply the ReLU function\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "# and finally max pool \n",
    "h_pool1 = max_pool_2x2(h_conv1) # It will reduce the image size to \"14x14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second Convolutional Layer\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2) # It will reduce the image size to \"7x7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Densely Connected Layer\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024]) \n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) # flatten\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dropout\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Readout Layer\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_conv)) # our loss\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) # our optimizer\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting dataset/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting dataset/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting dataset/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 8.0%\n",
      "step 1000, training accuracy 98.0%\n",
      "step 2000, training accuracy 98.0%\n",
      "step 3000, training accuracy 100.0%\n",
      "step 4000, training accuracy 92.0%\n",
      "step 5000, training accuracy 100.0%\n",
      "step 6000, training accuracy 100.0%\n",
      "step 7000, training accuracy 100.0%\n",
      "step 8000, training accuracy 98.0%\n",
      "step 9000, training accuracy 100.0%\n",
      "step 10000, training accuracy 100.0%\n",
      "step 11000, training accuracy 98.0%\n",
      "step 12000, training accuracy 100.0%\n",
      "step 13000, training accuracy 100.0%\n",
      "step 14000, training accuracy 100.0%\n",
      "step 15000, training accuracy 100.0%\n",
      "step 16000, training accuracy 100.0%\n",
      "step 17000, training accuracy 100.0%\n",
      "step 18000, training accuracy 100.0%\n",
      "step 19000, training accuracy 100.0%\n",
      "test accuracy 99.2%\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing\n",
    "\n",
    "# Re-import data for initializing batch\n",
    "mnist = input_data.read_data_sets(\"dataset/mnist\", one_hot=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(\n",
    "      tf.global_variables_initializer())  # initialize the variables we created\n",
    "  # run the training step 20000 times\n",
    "  for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 1000 == 0:\n",
    "      train_accuracy = accuracy.eval(feed_dict={\n",
    "          x: batch[0],\n",
    "          y_true: batch[1],\n",
    "          keep_prob: 1.0\n",
    "      })\n",
    "      print('step %d, training accuracy %.1f%%' % (i, train_accuracy * 100))\n",
    "    train_step.run(feed_dict={\n",
    "        x: batch[0],\n",
    "        y_true: batch[1],\n",
    "        keep_prob: 0.5\n",
    "    })  # feed into x, y_ and keep_prob for training\n",
    "\n",
    "  print('test accuracy %.1f%%' % (100 * accuracy.eval(feed_dict={\n",
    "      x: mnist.test.images,\n",
    "      y_true: mnist.test.labels,\n",
    "      keep_prob: 1.0\n",
    "  })))  # feed for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 109s 1us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 10)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# convert class vectors to binary vectors\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAACICAYAAAABDZUdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b7e3f07320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# transform an 3-channel image into one channel\n",
    "def grayscale(data, dtype='float32'):\n",
    "  # luma coding weighted average in video systems\n",
    "  r = np.asarray(.3, dtype=dtype)\n",
    "  g = np.asarray(.59, dtype=dtype)\n",
    "  b = np.asarray(.11, dtype=dtype)\n",
    "  rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "  # add channel dimension\n",
    "  rst = np.expand_dims(rst, axis=3)\n",
    "  return rst\n",
    "\n",
    "X_train_gray = grayscale(X_train)\n",
    "X_test_gray = grayscale(X_test)\n",
    "\n",
    "# plot a randomly chosen image\n",
    "img = round(np.random.rand() * X_train.shape[0])\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train[img], interpolation='none')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(\n",
    "    X_train_gray[img, :, :, 0], cmap=plt.get_cmap('gray'), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The code is credit to: \"http://www.itdadao.com/articles/c15a1243072p0.html\"\n",
    "def getHOGfeat(image,\n",
    "               stride=8,\n",
    "               orientations=8,\n",
    "               pixels_per_cell=(8, 8),\n",
    "               cells_per_block=(2, 2)):\n",
    "  cx, cy = pixels_per_cell\n",
    "  bx, by = cells_per_block\n",
    "  sx, sy, sz = image.shape\n",
    "  n_cellsx = int(np.floor(sx // cx))  # number of cells in x\n",
    "  n_cellsy = int(np.floor(sy // cy))  # number of cells in y\n",
    "  n_blocksx = (n_cellsx - bx) + 1\n",
    "  n_blocksy = (n_cellsy - by) + 1\n",
    "  gx = np.zeros((sx, sy), dtype=np.double)\n",
    "  gy = np.zeros((sx, sy), dtype=np.double)\n",
    "  eps = 1e-5\n",
    "  grad = np.zeros((sx, sy, 2), dtype=np.double)\n",
    "  for i in range(1, sx - 1):\n",
    "    for j in range(1, sy - 1):\n",
    "      gx[i, j] = image[i, j - 1] - image[i, j + 1]\n",
    "      gy[i, j] = image[i + 1, j] - image[i - 1, j]\n",
    "      grad[i, j, 0] = np.arctan(gy[i, j] / (gx[i, j] + eps)) * 180 / math.pi\n",
    "      if gx[i, j] < 0:\n",
    "        grad[i, j, 0] += 180\n",
    "      grad[i, j, 0] = (grad[i, j, 0] + 360) % 360\n",
    "      grad[i, j, 1] = np.sqrt(gy[i, j]**2 + gx[i, j]**2)\n",
    "  normalised_blocks = np.zeros((n_blocksy, n_blocksx, by * bx * orientations))\n",
    "  for y in range(n_blocksy):\n",
    "    for x in range(n_blocksx):\n",
    "      block = grad[y * stride:y * stride + 16, x * stride:x * stride + 16]\n",
    "      hist_block = np.zeros(32, dtype=np.double)\n",
    "      eps = 1e-5\n",
    "      for k in range(by):\n",
    "        for m in range(bx):\n",
    "          cell = block[k * 8:(k + 1) * 8, m * 8:(m + 1) * 8]\n",
    "          hist_cell = np.zeros(8, dtype=np.double)\n",
    "          for i in range(cy):\n",
    "            for j in range(cx):\n",
    "              n = int(cell[i, j, 0] / 45)\n",
    "              hist_cell[n] += cell[i, j, 1]\n",
    "          hist_block[(k * bx + m) * orientations:(k * bx + m + 1) * orientations] = hist_cell[:]\n",
    "      normalised_blocks[y, x, :] = hist_block / np.sqrt(\n",
    "          hist_block.sum()**2 + eps)\n",
    "  return normalised_blocks.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will take some minutes.\n"
     ]
    }
   ],
   "source": [
    "X_train_hog = []\n",
    "X_test_hog = []\n",
    "\n",
    "print('This will take some minutes.')\n",
    "\n",
    "for img in X_train_gray:\n",
    "  img_hog = getHOGfeat(img)\n",
    "  X_train_hog.append(img_hog)\n",
    "\n",
    "for img in X_test_gray:\n",
    "  img_hog = getHOGfeat(img)\n",
    "  X_test_hog.append(img_hog)\n",
    "\n",
    "X_train_hog_array = np.asarray(X_train_hog)\n",
    "X_test_hog_array = np.asarray(X_test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNN]\n",
      "Misclassified samples: 5334\n",
      "Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# p=2 and metric='minkowski' means the Euclidean Distance\n",
    "knn = KNeighborsClassifier(n_neighbors=11, p=2, metric='minkowski')\n",
    "\n",
    "knn.fit(X_train_hog_array, y_train.ravel())\n",
    "y_pred = knn.predict(X_test_hog_array)\n",
    "print('[KNN]')\n",
    "print('Misclassified samples: %d' % (y_test.ravel() != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear SVC]\n",
      "Misclassified samples: 4940\n",
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# C is the hyperparameter for the error penalty term\n",
    "# gamma is the hyperparameter for the rbf kernel\n",
    "svm_linear = SVC(kernel='linear', random_state=0, gamma=0.2, C=10.0)\n",
    "\n",
    "svm_linear.fit(X_train_hog_array, y_train.ravel())\n",
    "y_pred = svm_linear.predict(X_test_hog_array)\n",
    "print('[Linear SVC]')\n",
    "print('Misclassified samples: %d' % (y_test.ravel() != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
